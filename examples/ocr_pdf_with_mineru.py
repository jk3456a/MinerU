import copy
import glob
import os
import random
import traceback

import json

import time
import uuid

from mineru.backend.pipeline.model_init import MineruPipelineModel
from mineru.data.data_reader_writer import FileBasedDataWriter

from mineru.backend.pipeline.model_json_to_middle_json import result_to_middle_json as pipeline_result_to_middle_json
from mineru.backend.pipeline.pipeline_analyze import doc_analyze as pipeline_doc_analyze
from mineru.cli.common import convert_pdf_bytes_to_bytes_by_pypdfium2

# ==================== ÈÖçÁΩÆÂèÇÊï∞ ====================
# OCRÁõ∏ÂÖ≥ÈÖçÁΩÆ
DEFAULT_LANG = "ch"  # ÈªòËÆ§ËØ≠Ë®Ä
FORMULA_ENABLE = True  # ÊòØÂê¶ÂêØÁî®ÂÖ¨ÂºèËØÜÂà´
TABLE_ENABLE = False  # ÊòØÂê¶ÂêØÁî®Ë°®Ê†ºËØÜÂà´
PARSE_METHOD = "ocr"  # Ëß£ÊûêÊñπÊ≥ï
OCR_ENABLE = True  # ÊòØÂê¶ÂêØÁî®OCR

os.environ['MINERU_DONOT_CLEAN_MEM'] = 'true'
os.environ['MINERU_ASYNC_DEBUG'] = 'false'
# os.environ['MINERU_ASYNC_SYNC_INTERVAL'] = '4'

PROJECT_DIR = "/cache/lizhen/repos/MinerU"

# Ë∑ØÂæÑÈÖçÁΩÆ
DEFAULT_SAVE_DIR = PROJECT_DIR + "/output"  # ÈªòËÆ§‰øùÂ≠òÁõÆÂΩï
LIBGEN_PDF_DIR = PROJECT_DIR + "/input/sample_pdf_300"  # PDFÊ∫êÊñá‰ª∂ÁõÆÂΩï
PDF_LIST_FILE = PROJECT_DIR + "/input/pdf_list.txt"  # ÂæÖÂ§ÑÁêÜPDFÂàóË°®Êñá‰ª∂
LOCAL_IMAGE_TMP_DIR = PROJECT_DIR + "/tmp/images"  # ‰∏¥Êó∂ÂõæÁâáÁõÆÂΩï

# ÊµãËØï‰ªªÂä°Ë∑ØÂæÑÈÖçÁΩÆ
TEST_PDF_DIR = "/cache/lizhen/repos/MinerU/input/sample_pdf_300/*pdf"  # ÊµãËØïPDFÁõÆÂΩï
TEST_SAVE_DIR = "/cache/lizhen/repos/MinerU/output_test"  # ÊµãËØïÁªìÊûú‰øùÂ≠òÁõÆÂΩï

# ÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆ
MODEL_SOURCE = "modelscope"  # Ê®°ÂûãÊ∫ê
VIRTUAL_VRAM_SIZE = "24"  # ËôöÊãüÊòæÂ≠òÂ§ßÂ∞è(GB)
# MIN_BATCH_INFERENCE_SIZE = "512"  # ÊúÄÂ∞èÊâπÂ§ÑÁêÜÊé®ÁêÜÂ§ßÂ∞èÔºàÂèØÈÄâÔºâ

# ËÆæÂ§áÈÖçÁΩÆ
DEVICE = "cuda"  # ËøêË°åËÆæÂ§á

# ÊµãËØïÊ®°ÂºèÈÖçÁΩÆ
TEST_MODE = True  # ÊòØÂê¶ÂºÄÂêØÊµãËØïÊ®°ÂºèÔºàÂè™ÊµãËØï1‰∏™PDFÔºâ
TEST_SINGLE_PDF = True  # ÂçïPDFÊµãËØïÊ®°Âºè
TEST_NUM = 1


def infer_one_pdf(pdf_file_path, lang=DEFAULT_LANG):
    t0 = time.time()
    with open(pdf_file_path, 'rb') as fi:
        pdf_bytes = fi.read()
    t1 = time.time()
    new_pdf_bytes = convert_pdf_bytes_to_bytes_by_pypdfium2(pdf_bytes)
    t2 = time.time()
    print(f"read pdf file spend :{t1 - t0}, convert pdf spend :{t2 - t1}")
    formula_enable = FORMULA_ENABLE
    table_enable = TABLE_ENABLE
    pdf_name = os.path.basename(pdf_file_path)
    # ‰ΩøÁî®NVTXÂÆèÂ∑•ÂÖ∑ËøõË°åÊÄßËÉΩÂàÜÊûê
    from mineru.utils.nvtx_utils import nvtx_range
    
    with nvtx_range(f"pipeline_doc_analyze: {pdf_name}"):
        infer_results, all_image_lists, all_pdf_docs, lang_list, ocr_enabled_list = (
            pipeline_doc_analyze(
                [new_pdf_bytes],
                [lang],
                parse_method=PARSE_METHOD,
                formula_enable=formula_enable, table_enable=table_enable
            )
        )
    t3 = time.time()
    print(f"pipeline_doc_analyze spend:{t3 - t2}")
    model_list = infer_results[0]
    images_list = all_image_lists[0]
    pdf_doc = all_pdf_docs[0]
    _ocr_enable = OCR_ENABLE

    model_json = copy.deepcopy(model_list)

    local_image_dir = f"{LOCAL_IMAGE_TMP_DIR}/{pdf_name}"
    if not os.path.exists(local_image_dir):
        os.system(f"mkdir -p {local_image_dir}")
    image_writer = FileBasedDataWriter(local_image_dir)

    middle_json = pipeline_result_to_middle_json(
        model_list, images_list, pdf_doc, image_writer,
        lang, _ocr_enable, formula_enable
    )
    t4 = time.time()
    print(f"pipeline_result_to_middle_json spend:{t4 - t3}")
    print(f"sum time spend:{t4 - t0} doc_ana spend:{t3 - t2} percent:{(t3 - t2) / (t4 - t0) * 100}")
    ocr_result = {
        "middle_json": middle_json,
        "model_json": model_json
    }

    return ocr_result


def process_one_pdf_file(pdf_path, save_dir=None, lang=DEFAULT_LANG):
    if not save_dir:
        save_dir = DEFAULT_SAVE_DIR
    pdf_file_name = os.path.basename(pdf_path)
    # ‰øÆÊ≠£Ôºö‰øùÂ≠ò‰∏∫JSONÊñá‰ª∂ÔºåÈÅøÂÖç‰∏éÂéüPDFÊñá‰ª∂ÂêçÊ∑∑Ê∑Ü
    target_file = f"{save_dir}/{os.path.splitext(pdf_file_name)[0]}.json"
    if not os.path.exists(f"{save_dir}/"):
        os.system(f"mkdir {save_dir}/")
    # ‰∏∫‰∫ÜÊµãËØïÔºåÊöÇÊó∂‰∏çÁÆ°ÊúâÊ≤°ÊúâÈÉΩÊâßË°å
    # if os.path.exists(target_file):
    #     print(f"the pdf result exist...[{target_file}]")
    #     return

    infer_result = infer_one_pdf(pdf_path, lang=lang)
    infer_result['pdf_path'] = pdf_path
    res_json_str = json.dumps(infer_result, ensure_ascii=False, indent=2)

    with open(target_file, "w", encoding='utf-8') as fo:
        fo.write(res_json_str)
    
    print(f"‚úÖ PipelineÂ§ÑÁêÜÂÆåÊàêÔºåÁªìÊûú‰øùÂ≠òÂà∞: {target_file}")


def get_all_access_pdf_paths():
    print(glob.glob("/*"))
    pdf_files = glob.glob(LIBGEN_PDF_DIR + "/*pdf")  # ‰øÆÊ≠£Ë∑ØÂæÑ
    print(f"{len(pdf_files)} {pdf_files[:10]}")
    book_names = set()
    with open(PDF_LIST_FILE) as fi:
        for x in eval(fi.read()):
            book_name = os.path.basename(x)
            book_names.add(book_name)
    pdf_to_process_list = []
    for x in pdf_files:
        if os.path.basename(x) in book_names:
            pdf_to_process_list.append(x)
    random.shuffle(pdf_to_process_list)
    return pdf_to_process_list


def run_test_task():
    pdf_files = glob.glob(TEST_PDF_DIR)
    save_dir = TEST_SAVE_DIR
    
    print("=" * 80)
    print("MinerU PipelineÂêéÁ´ØÊÄßËÉΩÊµãËØï")
    print("=" * 80)
    
    if TEST_MODE and TEST_SINGLE_PDF:
        # ÊµãËØïÊ®°ÂºèÔºöÂè™ÊµãËØïÁ¨¨‰∏Ä‰∏™PDF
        if pdf_files:
            pdf_files = pdf_files[:TEST_NUM]
            print(f"üî¨ ÊµãËØïÊ®°ÂºèÔºöÂè™ÊµãËØï{TEST_NUM}‰∏™PDFÊñá‰ª∂")
        else:
            print("‚ùå Êú™ÊâæÂà∞PDFÊñá‰ª∂")
            return
    
    print(f"ÂæÖÊµãËØïPDFÊñá‰ª∂Êï∞Èáè: {len(pdf_files)}")
    if pdf_files:
        test_file = pdf_files[0]
        file_size = os.path.getsize(test_file) / 1024 / 1024  # MB
        print(f"ÊµãËØïÊñá‰ª∂: {os.path.basename(test_file)} ({file_size:.2f} MB)")
    
    success_count = 0
    failed_count = 0
    total_start_time = time.time()
    
    for idx, file_path in enumerate(pdf_files):
        if not os.path.exists(file_path):
            continue

        print(f"\nüìÑ Â§ÑÁêÜËøõÂ∫¶: {idx + 1}/{len(pdf_files)} - {os.path.basename(file_path)}")
        
        try:
            start_time = time.time()
            process_one_pdf_file(file_path, save_dir)
            process_time = time.time() - start_time
            print(f"‚úÖ PipelineÂ§ÑÁêÜËÄóÊó∂: {process_time:.2f}Áßí")
            success_count += 1
                
        except Exception as e:
            print(f"‚ùå Â§ÑÁêÜÂ§±Ë¥•: {e}")
            traceback.print_exc()
            print('=====' * 10)
            failed_count += 1

    total_time = time.time() - total_start_time
    print(f"\n" + "=" * 80)
    print(f"PipelineÂêéÁ´ØÊµãËØïÂÆåÊàê!")
    print(f"ÊàêÂäü: {success_count}, Â§±Ë¥•: {failed_count}")
    print(f"ÊÄªËÄóÊó∂: {total_time:.2f}Áßí")
    if success_count > 0 and 'file_size' in locals():
        avg_throughput = file_size * success_count / total_time
        print(f"Âπ≥ÂùáÂ§ÑÁêÜÈÄüÂ∫¶: {avg_throughput:.2f} MB/s")
    print("=" * 80)


def main():
    import glob
    # pdf_files = glob.glob("/home/admin/zhangxueren/sample_pdf_300/*pdf")
    # random.shuffle(pdf_files)
    pdf_files = get_all_access_pdf_paths()
    print(f"pdf_files cnt:{len(pdf_files)}")
    for idx, file_path in enumerate(pdf_files):
        if not os.path.exists(file_path):
            continue

        try:
            process_one_pdf_file(file_path)
        except Exception as e:
            print(e)
            traceback.print_stack()
            print('=====' * 10)


if __name__ == "__main__":
    os.environ["MINERU_MODEL_SOURCE"] = MODEL_SOURCE
    os.environ["MINERU_VIRTUAL_VRAM_SIZE"] = VIRTUAL_VRAM_SIZE
    # os.environ["MINERU_MIN_BATCH_INFERENCE_SIZE"] = MIN_BATCH_INFERENCE_SIZE
    start_time = time.time()
    # MineruPipelineModel(device=DEVICE)
    # main()
    # split_all_books()
    # copy_left_books()
    run_test_task()
    total_time = time.time() - start_time
    print(f'Total time: {total_time:.2f} seconds')
